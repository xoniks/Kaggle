{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Application with a Real Data Set - Draft Version 1\n",
    "## https://www.kaggle.com/c/santander-customer-satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set\n",
    "\n",
    "- Santander Bank is asking to help identify dissatisfied customers in their relationship with hundreds of anonymized features. Please visit the website and read details about it.\n",
    "\n",
    "- 743 columns (ID, TARGET, and features), 76020 rows: train and test data sets.\n",
    "\n",
    "- The \"TARGET\" column is the variable to predict. It equals one for unsatisfied customers and 0 for satisfied customers.\n",
    "\n",
    "- Data file descriptions:\n",
    "\n",
    "        train.csv - the training set including the target\n",
    "        test.csv - the test set without the target\n",
    "        sample_submission.csv - a sample submission file in the correct format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "- The task: \n",
    "    1. to describe the data set\n",
    "        - data type for each column \n",
    "        - missingness\n",
    "        - univariate summaries\n",
    "        - bivariate summaries\n",
    "            - associations\n",
    "            - correlations\n",
    "            - patterns\n",
    "        - multivariate summaries\n",
    "        - more\n",
    "    2. to predict the probability that each customer in the test set is an unsatisfied customer.\n",
    "    3. to predict if a customer is satisfied or dissatisfied with their banking experience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping\n",
    "\n",
    "Know: \n",
    "- where you are working\n",
    "- version check\n",
    "- shorcuts: https://youtu.be/d0oBRIONOEw\n",
    "\n",
    "Basic packs to use:\n",
    "- numpy\n",
    "- pandas\n",
    "- seaborn\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\newstu\\\\Desktop\\\\Data\\\\kaggle'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory working\n",
    "%pwd #look at the current work dir. import os\n",
    "#%cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Source and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and load the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check version\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from directory\n",
    "train = pd.read_csv(\"train.csv\", index_col='ID') # the train dataset is now a Pandas DataFrame\n",
    "test = pd.read_csv(\"test.csv\", index_col='ID') # the train dataset is now a Pandas DataFrame\n",
    "#train = pd.read_csv(\"Documents/GitHub/ML/santander-customer-satisfaction/train.csv\", index_col='ID') # the train dataset is now a Pandas DataFrame\n",
    "#test = pd.read_csv(\"Documents/GitHub/ML/santander-customer-satisfaction/test.csv\", index_col='ID') # the train dataset is now a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Alternative way if data is undet the same folder\n",
    "train = pd.read_csv(\"train.csv\")                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Wrangling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use train data set for EDA\n",
    "# Look the number of rows and columns\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                           int64\n",
       "var3                         int64\n",
       "var15                        int64\n",
       "imp_ent_var16_ult1         float64\n",
       "imp_op_var39_comer_ult1    float64\n",
       "                            ...   \n",
       "saldo_medio_var44_hace3    float64\n",
       "saldo_medio_var44_ult1     float64\n",
       "saldo_medio_var44_ult3     float64\n",
       "var38                      float64\n",
       "TARGET                       int64\n",
       "Length: 371, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data types\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Check out the data types, number of entries and other details\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "3                      0.0                      0.0  ...   \n",
       "4                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the first 5 rows of the data set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                         0\n",
       "var3                       0\n",
       "var15                      0\n",
       "imp_ent_var16_ult1         0\n",
       "imp_op_var39_comer_ult1    0\n",
       "                          ..\n",
       "saldo_medio_var44_hace3    0\n",
       "saldo_medio_var44_ult1     0\n",
       "saldo_medio_var44_ult3     0\n",
       "var38                      0\n",
       "TARGET                     0\n",
       "Length: 371, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given we couldn't see NaNs from the df.info(), let's do this another way\n",
    "train.isnull().sum() #.nlargest() #.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of columns with all zeros as average\n",
    "np.sum(train.mean()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns have zeros?\n",
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with all zeros\n",
    "zero_mean = (train.mean()==0).to_frame(name='ZeroMean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               ZeroMean\n",
      "ind_var2_0                         True\n",
      "ind_var2                           True\n",
      "ind_var27_0                        True\n",
      "ind_var28_0                        True\n",
      "ind_var28                          True\n",
      "ind_var27                          True\n",
      "ind_var41                          True\n",
      "ind_var46_0                        True\n",
      "ind_var46                          True\n",
      "num_var27_0                        True\n",
      "num_var28_0                        True\n",
      "num_var28                          True\n",
      "num_var27                          True\n",
      "num_var41                          True\n",
      "num_var46_0                        True\n",
      "num_var46                          True\n",
      "saldo_var28                        True\n",
      "saldo_var27                        True\n",
      "saldo_var41                        True\n",
      "saldo_var46                        True\n",
      "imp_amort_var18_hace3              True\n",
      "imp_amort_var34_hace3              True\n",
      "imp_reemb_var13_hace3              True\n",
      "imp_reemb_var33_hace3              True\n",
      "imp_trasp_var17_out_hace3          True\n",
      "imp_trasp_var33_out_hace3          True\n",
      "num_var2_0_ult1                    True\n",
      "num_var2_ult1                      True\n",
      "num_reemb_var13_hace3              True\n",
      "num_reemb_var33_hace3              True\n",
      "num_trasp_var17_out_hace3          True\n",
      "num_trasp_var33_out_hace3          True\n",
      "saldo_var2_ult1                    True\n",
      "saldo_medio_var13_medio_hace3      True\n"
     ]
    }
   ],
   "source": [
    "zero_mean = zero_mean.loc[zero_mean.ZeroMean]\n",
    "print(zero_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_var2_0', 'ind_var2', 'ind_var27_0', 'ind_var28_0', 'ind_var28', 'ind_var27', 'ind_var41', 'ind_var46_0', 'ind_var46', 'num_var27_0', 'num_var28_0', 'num_var28', 'num_var27', 'num_var41', 'num_var46_0', 'num_var46', 'saldo_var28', 'saldo_var27', 'saldo_var41', 'saldo_var46', 'imp_amort_var18_hace3', 'imp_amort_var34_hace3', 'imp_reemb_var13_hace3', 'imp_reemb_var33_hace3', 'imp_trasp_var17_out_hace3', 'imp_trasp_var33_out_hace3', 'num_var2_0_ult1', 'num_var2_ult1', 'num_reemb_var13_hace3', 'num_reemb_var33_hace3', 'num_trasp_var17_out_hace3', 'num_trasp_var33_out_hace3', 'saldo_var2_ult1', 'saldo_medio_var13_medio_hace3']\n"
     ]
    }
   ],
   "source": [
    "# We can get rid of the columns with all zeros, there is no information to gain from them\n",
    "# This is dangerous way to do!\n",
    "remove_features = list(zero_mean.index)\n",
    "print(remove_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 337)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(remove_features, axis=1)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the number of columns that decreased from original 371 to 337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of columns with all zeros\n",
    "np.sum(train.mean()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniqueness of values using train.unique for each column\n",
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>var3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76015</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76016</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76017</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76018</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76019</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76020 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TARGET  var3\n",
       "0           0     2\n",
       "1           0     2\n",
       "2           0     2\n",
       "3           0     2\n",
       "4           0     2\n",
       "...       ...   ...\n",
       "76015       0     2\n",
       "76016       0     2\n",
       "76017       0     2\n",
       "76018       0     2\n",
       "76019       0     2\n",
       "\n",
       "[76020 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at classes of the target \n",
    "train[['TARGET', 'var3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.960431\n",
       "1    0.039569\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percent of happy-unhappy customers\n",
    "train['TARGET'].value_counts() / train.shape[0]\n",
    "\n",
    "# See this data is a unbalanced data. When modeling, this produces an issue tht needs to be handled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73012</td>\n",
       "      <td>96.043147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3008</td>\n",
       "      <td>3.956853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET  Percentage\n",
       "0   73012   96.043147\n",
       "1    3008    3.956853"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Happy customers: TARGET==0 vs Unhappy custormers: TARGET==1\n",
    "df = pd.DataFrame(train.TARGET.value_counts())\n",
    "df['Percentage'] = 100*df['TARGET']/train.shape[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discover data related issues, type issues, all issues before running EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 337 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the range of each feature and target values\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a code to get all the ranges of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ab = []\n",
    "\n",
    "for i in train.columns:\n",
    "    ab.append([i, train[i].min(),train[i].max(), train[i].max()-train[i].min()])\n",
    "\n",
    "#print(ab) #see this is not good way to print!\n",
    "\n",
    "\n",
    "#? Research: Effect of Kurtosis and Skewness on Scaling Method (Feature Engineering)\n",
    "#? Shape of Distri\n",
    "#? Use of Skewness in Modeling. Next Topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>151838.00</td>\n",
       "      <td>151837.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>var3</td>\n",
       "      <td>-999999.0</td>\n",
       "      <td>238.00</td>\n",
       "      <td>1000237.00</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>var15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>105.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imp_ent_var16_ult1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>72301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imp_op_var39_comer_ult1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12888.03</td>\n",
       "      <td>12888.03</td>\n",
       "      <td>66075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1          2           3      4\n",
       "0                       ID       1.0  151838.00   151837.00      0\n",
       "1                     var3 -999999.0     238.00  1000237.00     75\n",
       "2                    var15       5.0     105.00      100.00      0\n",
       "3       imp_ent_var16_ult1       0.0  210000.00   210000.00  72301\n",
       "4  imp_op_var39_comer_ult1       0.0   12888.03    12888.03  66075"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab = []\n",
    "\n",
    "for i in train.columns:\n",
    "    ab.append([i, train[i].min(),train[i].max(), train[i].max()-train[i].min(),len(train[train[i] == 0])])\n",
    "\n",
    "#print(ab) #see this is not good way to print!\n",
    "df = pd.DataFrame(ab)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "4 columns passed, passed data had 5 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    496\u001b[0m         result = _convert_object_array(\n\u001b[1;32m--> 497\u001b[1;33m             \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[1;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    580\u001b[0m             raise AssertionError(\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m                 \u001b[1;34mf\"{len(content)} columns\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 4 columns passed, passed data had 5 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-3a14bdc03d4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Give column names and make data frame of pandas, then print\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'cols'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'range'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#add more statistic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_ranges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mab\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_ranges\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    472\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# columns if columns is not None else []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    498\u001b[0m         )\n\u001b[0;32m    499\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 4 columns passed, passed data had 5 columns"
     ]
    }
   ],
   "source": [
    "# Give column names and make data frame of pandas, then print\n",
    "cols = ['cols','min','max', 'range'] #add more statistic\n",
    "df_ranges = pd.DataFrame(ab,columns=cols)\n",
    "df_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When scaling, high values will skew the transformation. So use percentile or robust scaling method\n",
    "# How to handle these high values or coded values in a variable? -999999\n",
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranges.sort_values(by=['range'], ascending=False, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See one -999999 in var3\n",
    "train.var3.value_counts() #all\n",
    "train.var3.value_counts()[:10] #first 10 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dig into issues and redefine\n",
    "train.loc[train.var3==-999999].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -999999 with 0\n",
    "train = train.replace(-999999,0)\n",
    "train.loc[train.var3==-999999].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature that points this unusual values\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task. Your observations and data wrangling to discover issues\n",
    "Please play with the data set. Use basic pandas codes and observe and explore issues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Exploratory Data Analysis (EDA) with Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram of Each Feature\n",
    "# This will generate bar charts/histogram for each. Later, after feature reductions, you can use it again.\n",
    "class color:\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'\n",
    "for i, col in enumerate(train.columns):\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(5,3)) \n",
    "    plt.hist(train[col], bins=30)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "df_corr = train.corr()\n",
    "print(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task. Sort, get highest correlations (+-) using abs(), unstack(), sort_values(kind=\"quicksort\") and Sprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pick some variables and get correlation\n",
    "train[['var36', 'num_var5', 'var38', 'TARGET']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap using seaborn\n",
    "# You may want to run this after eliminating features\n",
    "import seaborn as sns\n",
    "sns.heatmap(train[['var36', 'num_var5', 'var38', 'TARGET']].corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with fitted line\n",
    "sns.lmplot(x='var38', y='num_var5', data=train)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the plot. Discuss does this tell us anythings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='var38', y='num_var5', hue='TARGET', data=train, fit_reg=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(16,9))\n",
    "train_copy=train.drop(['var36','var38','num_var5', 'TARGET'],axis=1)\n",
    "sns.boxplot(data=train['var38'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Discuss: On the same scale plot of fatures, it is not good idea. Need to do seperate or scale.\n",
    "# Task: How to scale and how to seperately plot boxplots?\n",
    "#group variables with features just in continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=train[['var38']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIN-MAX SCALING\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "min_max_scaled = min_max.fit_transform(train['var38'].values.reshape(-1, 1))\n",
    "df_min_max = pd.DataFrame(min_max_scaled, columns=['Min_max_var38'])\n",
    "\n",
    "print('MIN-MAX SCALING')\n",
    "display(df_min_max.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(7,17))\n",
    "sns.boxplot(data=df_min_max['Min_max_var38'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change figure size\n",
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "sns.violinplot(x='TARGET', y='var38', data=train)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plot\n",
    "sns.distplot(train['var36'], color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plot\n",
    "sns.countplot(x='var36', data=train)\n",
    "\n",
    "# Rotate labels\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint plot: bivariate\n",
    "# This take time\n",
    "sns.jointplot(train.var38, train.num_var5, data=train, kind='kde', color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotly\n",
    "\n",
    "It is interactive effective tool for data visualization and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "fig = px.scatter(train, x='var38', y='num_var5')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# This may not work right away. May need to install pack from pip or terminal. Jupyter-lab has issues with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hovering features\n",
    "fig = px.scatter(train, x='var38', y='num_var5', hover_data=['TARGET'])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing total along with hovering features\n",
    "fig = px.scatter(train, x='var38', y='num_var5', hover_data=['TARGET'], size='var36', color='Grey')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing total along with hovering features\n",
    "fig = px.box(train[['var36','var38']],  color='blue')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: get correlation matrix as corr_matrix, list it, label it by labels=list(corr_matrix), use px.imshow(corr_matrix,x=labels, y=labels) and fig.show()\n",
    "# px.histogram(), px.density_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: use of list(), range(), list(rage(train.shape[0])), .sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usefel codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is data set: Then\n",
    "\n",
    "# if you want to get the rows where the color is green, then you’ll need to apply:\n",
    "df.loc[df[‘Color’] == ‘Green’]\n",
    "\n",
    "# Green and Rectangle\n",
    "df.loc[(df[‘Color’] == ‘Green’) & (df[‘Shape’] == ‘Rectangle’)]\n",
    "\n",
    "# Use of OR\n",
    "df.loc[(df[‘Color’] == ‘Green’) | (df[‘Shape’] == ‘Rectangle’)]\n",
    "\n",
    "#To get all the rows where the price is equal or greater than 10, you’ll need to apply this condition:\n",
    "df.loc[df[‘Price’] >= 10]\n",
    "\n",
    "#You can use the combination of symbols != to select the rows where the price is not equal to 15:\n",
    "df.loc[df[‘Price’] != 15]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3b: Issues with This Type of Data\n",
    "\n",
    "- Too many zeros. How to handle?\n",
    "\n",
    "- How to detect associations among any two combination? (EDA with no Target) \n",
    "\n",
    "- Association with Target Variable (so feature selection can be employed)\n",
    "\n",
    "- When to Use and Why Association?\n",
    "    - To measure association (chi-sq, RR, OR, conditional proportion etc.) between two categorical variables\n",
    "\n",
    "- When to Use and Why Correlation?\n",
    "    - To measure between two numerical linear relationships\n",
    "    \n",
    "\n",
    "- When to not Use?\n",
    "\n",
    "- Alternatives?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search: Why Mr. B write this? Make critiques\n",
    "\n",
    "Notice how we can't even see the correlation matrix for all of the variables due to large number of columns. We will try the following methods:\n",
    "    1. Melt the data that will result into decrease in number of columns but increase in number of rows. \n",
    "    2. Shrink the size of the columns to the most important 10 features by using Univariate feature selection technique."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3c: Feature Importance and Selection\n",
    "\n",
    "This is just one application. Many methods and approach exist. The instructor will briefly go over the file, 'Feature Engineering, Data Reduction, and Curse.doc'\n",
    "\n",
    "In general, the choice of evaluation metric heavily influences the algorithm, and it is these evaluation metrics which distinguish between the three main categories of feature selection algorithms: \n",
    "\n",
    "- wrappers, \n",
    "- filters and \n",
    "- embedded methods.\n",
    "\n",
    "Filters are most common and cheap:\n",
    "\n",
    "![image.png](attachment:image.png)![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scale the features first: Why?\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x = train.drop(['TARGET'], axis=1)\n",
    "y = train['TARGET']\n",
    "scaler = MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SelectKBest class to extract the 10 features that best explains the association relationships between Target and Univariate feature (chi-squa results are ranked) \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2 #see other options https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(x_scaled, y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(x.columns)\n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "featureScores.columns = ['Feature', 'Score']\n",
    "print(featureScores.nlargest(10, 'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_10best_chi = ['num_meses_var5_ult3', 'ind_var5', 'ind_var30', \n",
    "           'var36', 'ind_var8_0', 'ind_var13', \n",
    "           'ind_var13_0', 'ind_var12_0', \n",
    "          'num_var5', 'ind_var13_corto', 'TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we have 11+1 features from train set to proceed\n",
    "sub_train = train[columns_10best_chi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And take the same features from test set\n",
    "sub_test = test[columns_10best_chi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sub_train.shape, sub_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Elimination Techniques\n",
    "\n",
    "Univariate Feature Selection from Scikit\n",
    "\n",
    "    2.1. GenericUnivarietSelect\n",
    "    2.2. SelectKBest\n",
    "    2.3. SelectPercentile\n",
    "    2.4. SelectFpr\n",
    "    2.5. SelectFdr\n",
    "    2.6. SelectFwe\n",
    "    2.7. chi2\n",
    "    2.8. f_classif\n",
    "    2.9. f_regerssion\n",
    "    2.10. mutual_info_classif\n",
    "    2.11. mutual_info_regression\n",
    "    \n",
    "Also usefel methods below. Plase play wtih these codes. May need fixing:\n",
    "\n",
    "0) Removing Constant Features\n",
    "1) Removing Quasi-constant: Quasi-constant features are those that show the same value for the great majority of the observations of the dataset.\n",
    "2) Removing Feature From Low Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Removing Constant Features\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# fit finds the features with zero variance\n",
    "sel = VarianceThreshold(threshold=0)\n",
    "sel.fit(train)\n",
    "X1 = train.drop(columns=train.columns[~sel.get_support()])\n",
    "X1t = test.drop(columns=test.columns[~sel.get_support()])\n",
    "\n",
    "print(X1.shape)\n",
    "print(X1t.shape)\n",
    "\n",
    "#print(f'New sahape {X1.shape} number of feature removed {X_train.shape[1] - X1.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Removing Quasi-constant: Quasi-constant features are those that show the same value for the great majority of the observations of the dataset.\n",
    "\n",
    "sel_quasi = VarianceThreshold(threshold=0.01)  # 0.1 indicates 99% of observations approximately\n",
    "sel_quasi.fit(X1)\n",
    "X2 = X1.drop(columns=X1.columns[~sel_quasi.get_support()])\n",
    "X2t = X1t.drop(columns=X1t.columns[~sel_quasi.get_support()])\n",
    "\n",
    "print(f'New sahape {X2.shape} number of feature removed {X1.shape[1] - X2.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Removing Feature From Low Variance\n",
    "#VarianceThreshold is a simple baseline approach to feature selection. It removes all features whose variance doesn’t meet some threshold. By default, it removes all zero-variance features, i.e. features that have the same value in all samples.\n",
    "#As an example, suppose that we have a dataset with boolean features, and we want to remove all features that are either one or zero (on or off) in more than 80% of the samples. Boolean features are Bernoulli random variables, and the variance of such variables is given by\n",
    "#so we can select using the threshold .8 * (1 - .8):\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# First Example \n",
    "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X)\n",
    "\n",
    "print(f'Variance value per columng {sel.variances_}, threshold {sel.threshold : 2.2f}')\n",
    "\n",
    "sel = VarianceThreshold(threshold=0.01)\n",
    "result = pd.DataFrame(sel.fit_transform(df_train))\n",
    "\n",
    "sel.variances_\n",
    "\n",
    "# Find the remaining column id\n",
    "remain_features_id = np.where(sel.variances_ > sel.threshold)\n",
    "\n",
    "# Assign remaining column name\n",
    "result.columns = df_train.columns[remain_features_id]\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "Are all of these categorical variables? is it a problem when building predictive modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need Powerful Tools and Packs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package 1: Pandas-Profiling\n",
    "\n",
    "Import the pack or upoad it from https://github.com/pandas-profiling/pandas-profiling.\n",
    "\n",
    "Shortly, this generates profile reports from a pandas DataFrame. The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install here or using pip: >> pip install pandas-profiling\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need if not running\n",
    "sub_train.profile_report(style={‘full_width’:True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(sub_train, title=\"Pandas Profiling Report\")\n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(\"your_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE__: Pandas-profiling may NOT process the data due to its size and not enough compute resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package 2:  ClfAutoEDA\n",
    "\n",
    "- Read the article https://medium.com/analytics-vidhya/automated-eda-for-classification-77c25b847e43\n",
    "- Download the py code in the directory you are working: https://github.com/jatinkataria94/EDA-Classification/blob/master/ClfAutoEDA.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the autoEDA module\n",
    "from ClfAutoEDA import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Just play with small data portion\n",
    "#Setting parameter values\n",
    "target_variable_name='TARGET'\n",
    "labels=['Unhappy','Happy']\n",
    "#Calling EDA function with parameters of choice\n",
    "df_processed,num_features,cat_features=EDA(df=sub_train,labels=labels,\n",
    "                                         target_variable_name=target_variable_name,\n",
    "                                         data_summary_figsize=(6,6),\n",
    "                                         corr_matrix_figsize=(6,6), \n",
    "                                         corr_matrix_annot=True,\n",
    "                                         pairplt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE__: Pandas-profiling couldn't process the data due to its size and not enough compute resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pack 3. Sweetviz\n",
    "\n",
    "Read the article https://towardsdatascience.com/powerful-eda-exploratory-data-analysis-in-just-two-lines-of-code-using-sweetviz-6c943d32f34\n",
    "\n",
    "Install it using pip install sweetviz and run the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will tke too much time if \n",
    "my_report = sweetviz.compare([sub_train, \"Train\"], [sub_test, \"Test\"], \"TARGET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_report.show_html(\"Report.html\") # Not providing a filename will default to SWEETVIZ_REPORT.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pack 4. Pycaret\n",
    "\n",
    "A complex level pack that does all!\n",
    "\n",
    "Read the article https://github.com/pycaret/pycaret and examples https://github.com/pycaret/pycaret/tree/master/examples.\n",
    "\n",
    "Install it using pip install pycaret.\n",
    "\n",
    "Practice it with the dataset here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Resources to Practice\n",
    "- https://www.kaggle.com/c/santander-customer-satisfaction and see many notebooks prepared\n",
    "- https://www.kaggle.com/cast42/exploring-features ==> nice notebook to practice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
